\section{Andra ordningens linjära ODE:er}

\noindent Vi kommer introducera dessa och tala om \textit{homogena ekvationer}.
\par\bigskip

\begin{theo}[Andra ordningens ODE]{thm:seconddegode}
  En allmän andra ordningens ODE är:


  \begin{equation*}
    \begin{gathered}
      G(x,y,y^{\prime}, y^{\prime\prime})=0
    \end{gathered}
  \end{equation*}
  \par\bigskip
  \noindent Om vi kan isolera $y^{\prime\prime}$ får vi:


  \begin{equation*}
    \begin{gathered}
      y^{\prime\prime}=F(x,y,y^{\prime})
    \end{gathered}
  \end{equation*}
\end{theo}
\par\bigskip
\noindent Vi kommer fokusera främst på linjära ODE:er.
\par\bigskip

\begin{theo}[Linjär ODE]{thm:linearode}
  En ODE som kan skrivas på formen:


  \begin{equation*}
    \begin{gathered}
      A(x)y^{\prime\prime}+B(x)y^{\prime}+C(x)y=F(x)
    \end{gathered}
  \end{equation*}
  \par\bigskip
  \noindent Vi kommer anta att $A, B, C, F$ är kontinuerliga

\end{theo}

\subsection{Exempel}\hfill\\

\noindent Exempel på en linjär ODE (Bessel-ekvationen)

\begin{equation*}
  \begin{gathered}
    x^2y^{\prime\prime}+xy^{\prime}+(x^2-\alpha^2)y=0\\
    y^{\prime\prime} = (y+1)^2y^{\prime}+y^2
  \end{gathered}
\end{equation*}
\par\bigskip

\noindent Exempel på en icke-linjär 2:a ordningens ODE:

\begin{equation*}
  \begin{gathered}
    y^{\prime\prime} = (y+1)^2y^{\prime}+y^2
  \end{gathered}
\end{equation*}
\par\bigskip

\begin{theo}[Homogen ekvation]{thm:homogenous}
  Om $F(x)=0$ kallas ekvationen för \textit{homogen}. Annars kallas den inhomogen.
  \par\bigskip
  \noindent Den \textit{associerade homogena} ekvationen är en ODE där vi ansätter $F(x)=0$, det vill säga om vi tar ekvationen från sats 6.2 och sätter $F(x)=0$ så är det vår associerade homogena ekvationen.
\end{theo}
\par\bigskip

\noindent Exempel:


\begin{equation*}
  \begin{gathered}
    3y^{\prime\prime}+(2+x)y^{\prime}+y=\cos(x)
  \end{gathered}
\end{equation*}

\noindent har den associerade homogena ekvationen:


\begin{equation*}
  \begin{gathered}
    3y^{\prime\prime}+(2+x)y^{\prime}+y=0
  \end{gathered}
\end{equation*}
\par\bigskip

\noindent Notera här att vi kan multiplicera vår associerade ekvation med vad som, detta kommer inte ändra vår lösningsmängd.
\par\bigskip

\noindent IVP existerar för andra ordningens ODE:er. För en fullständig lösning kommer vi kräva 2 initalvillkor, men vi kan få en \textit{parametriserad} lösningsmängd om vi har 1.
\par\bigskip
\pagebreak

\begin{theo}[Existens]{thm:exanduniq}
  Betrakta 

  \begin{equation*}
    \begin{rcases*}
      y^{\prime\prime}+p(x)y^{\prime}+q(x)y=f(x)\\
      y(a)=b_0, \text{  } y^{\prime}(a)=b_1
    \end{rcases*}
  \end{equation*}
  \par\bigskip
  \noindent Om $p, q$ är kontinuerliga på ett intervall $I$ som innehåller $a$ (våran startpunkt), då finns exakt en lösning $y=y(x)$ och den är definierad på hela intervallet $I$.
\end{theo}
\par\bigskip

\noindent Kommentar: Första ord. ODE:er har endast en lösning som går igenom en punkt $(x_0,y_0)$. För andra ordningen har vi en lösning för varje lutning också!
\par\bigskip
\noindent Kommentar: Det visar sig att vi kommer stöta på en massa linjär algebra. Kanske inte för 2:a ordningens, men för första är det användbart. För 3:e ordningen och n:e ordningen går det m.h.a linjär algebra att generalisera ganska enkelt, vi kommer bara få större matriser.
\par\bigskip

\noindent Kommentar: Vissa lösningar kommer vi se blir system av mindre ordningens ODE:er, detta går också att definiera och lösa m.h.a linjär algebra.

\par\bigskip

\subsection{Homogena ekvationer}\hfill\\

\noindent  För att förstå inhomogena måste vi först förstå homogena. Detta kanske inte är tydligt varför, men det kommer vi se senare när vi diskuterar andra ekvationer. Vi påminner oss om att en homogen ekvation är på formen:


\begin{equation*}
  \begin{gathered}
    A(x)y^{\prime\prime}+B(x)y^{\prime}+y=0
  \end{gathered}
\end{equation*}
\par\bigskip

\begin{theo}
  OOm $y_1$ och $y_2$ löser den homogena ekvationen på ett intervall $I$, då löser även $y=C_1y_1+C_2y_2$ ekvationen för alla konstanter $C_1, C_2$ på $I$
\end{theo}
\par\bigskip
\noindent Notera här att det i princip blir en linjärkombination, varpå namnet "linjär ODE" kommer ifrån. Beviset lämnas som övning till läsaren.

\noindent Exempel:

\begin{equation*}
  \begin{gathered}
    y_1=e^x \text{ och } y_2=xe^x \text{ är lösningar till}\\y^{\prime\prime}-2y^{\prime}+y=0\\
    \text{Då är } y= C_1e^x+C_2xe^x = (C_1+C_2x)e^x \text{ också en lösning}
  \end{gathered}
\end{equation*}
\par\bigskip

\noindent Varför vill man ha detta? Om vi har ett IVP så vill vi att lösningen skall ha ett specifikt värde. Då kan vi kombinera lösningar för att få det svaret vi söker.
\par\bigskip

\noindent Lösningsmetod (idé):

\begin{itemize}
  \item Hitta 2 lösningar $y_1$ och $y_2$
  \item Ta deras linjärkombination $y=C_1y_1+C_2y_2$
  \item Använd initalvillkor för att bestämma $C_1, C_2$
\end{itemize}

\noindent Funkar sista punkten verkligen alltid? Svaret är ja, om man väljer $y_1$ och $y_2$ på rätt sätt. Men detta implicerar att det finns ett fel sätt också. Om vi exempelvis får att $y=y^{\prime}$ så kan vi inte bestämma $C_1, C_2$ 
\par\bigskip
\pagebreak

\begin{theo}[Linjärt oberoende]{thm:linindep}
  Två funktioner $f,g$ är linjärt oberoende om vi \textit{inte} har:

  \begin{equation*}
    \begin{gathered}
      f = kg \text{ eller } g=kf \text{ för någon konstant } k\in\R
    \end{gathered}
  \end{equation*}
  \par\bigskip
  \noindent Det som är viktigt är att ingen av de ($k$ eller funktionerna) är noll, ty annars kan vi dela på noll.
\end{theo}
\par\bigskip

\noindent Exempel:


\begin{equation*}
  \begin{gathered}
    \begin{rcases*}
      \sin(x) \text{ och } \cos(x) \text{ är linjärt oberoende}\\
      e^x \text{ och } xe^x\\
      x+1 \text{ och } x^2
    \end{rcases*}\text{Linjärt oberoende}
  \end{gathered}
\end{equation*}
\par\bigskip

\noindent Man kan verifiera om de är linj. ober. genom att ta $\dfrac{f}{g}$, om de inte är lika med en konstant så är de oberoende. Exempelvis är då $e^{x+1}$ och $e^x$ linjärt beroende. Det är inte alltid lätt att se, exempelvis:


\begin{equation*}
  \begin{gathered}
    \sin(2x) \text{ och } \sin(x)\cos(x) \text{ är linjärt beroende ty:}\\
    \sin(2x)=2\sin(x)\cos(x)
  \end{gathered}
\end{equation*}
\par\bigskip

\noindent Ett verktyg som är användbart när man studerar dessa typer av ODE:er är \textit{Wronskianen}.
\par\bigskip

\begin{theo}[Wronskianen]{thm:wron}
  Wronskianen av 2 deriverbara funktioner $f,g$ är:


  \begin{equation*}
    \begin{gathered}
      W(f,g)= \det(\begin{pmatrix}f&g\\f'&g'\end{pmatrix}) = fg'-f'g
    \end{gathered}
  \end{equation*}
\end{theo}
\par\bigskip

\begin{lem}
  OOm $f,g$ är deriverbara på intervallet $I$ och är linjärt beroende på $I$, då är $W(f,g)=0 \text{  } \forall x\in I$. Om vi får oberoende ekvationer, då kan vi hitta en lösning m.h.a lösningsidén.
\end{lem}
\par\bigskip

\begin{prf}[Wronskianen]{thm:wron}
  Om $f,g$ är linjärt beroende så är $f=kg$ eller $g=kf$. Vi stoppar in det i uttrycket för Wronskianen:

  \begin{equation*}
    \begin{gathered}
      W(f,g)=\det(\begin{pmatrix}f&g\\f'&g'\end{pmatrix})= \det(\begin{pmatrix}kg&g\\kg'&g'\end{pmatrix}) = kgg'-kg'g = 0
    \end{gathered}
  \end{equation*}
  \par\bigskip
  \noindent Det funkar tyvärr inte åt andra hållet, det vill säga om determinanten är noll så är de inte alltid linjärt beroende.
\end{prf}
\par\bigskip
\noindent Motexempel:

\begin{equation*}
  \begin{gathered}
    f=x^2 \text{  }, g=|x|x
  \end{gathered}
\end{equation*}
\noindent Dessa är linjärt oberoende men har noll-determinant.
\par\bigskip
\noindent Hur vet vi att det ens finns 2 linjärt oberoende lösningar så att vi kan få vårat coola svar? Det visar sig att det inte är jättekrångligt att visa! Vi kan använda satsen om existens och unikhet:


\begin{equation*}
  \begin{gathered}
    y^{\prime\prime}+p(x)y^{\prime}+g(x)=0\\
    y(a)=0, \text{  } y^{\prime}(a)=1 \Rightarrow \text{ det finns en lösning } y_1 \text{ enligt existens och unikhetssatsen}\\
    y(a)=1, \text{  } y^{\prime}(a)=0 \text{  det finns en lösning $y_2$ enligt existens och unikhetssatsen}\\
    \text{Då måste vi kolla så att } y_1, y_2 \text{ är linjärt oberoende (Wronskianen nollskilld):}\\
    W(y_1,y_2)(a)= \det(\begin{pmatrix}y_1(a)&y_2(a)\\y_1'(a)&y_2'(a)\end{pmatrix}) = y_1(a)y_2'(a)-y_1'(a)y_2(a) = 0\cdot0-1\cdot1=-1\neq0\\
    \text{Alltså linjärt oberoende}
  \end{gathered}
\end{equation*}
\par\bigskip

\begin{theo}
  Låt $y_1$ och $y_2$ vara linjärt oberoende lösningar till:

  \begin{equation*}
    \begin{gathered}
      y^{\prime\prime}+p(x)y^{\prime}+q(x)y=0 \text{ där $p,q$ är kontinuerliga på intervallet $I$}
    \end{gathered}
  \end{equation*}
  \par\bigskip
  \noindent Då är alla lösningar på formen $y=C_1y_1+C_2y_2$
\end{theo}
\par\bigskip

\begin{theo}[Fundamental lösningsmängd]{def:fund}
  Två linjärt oberoende lösnignar kallas för en fundamental lösningsmängd
\end{theo}
\par\bigskip

\begin{prf}
  AAntag att vi har en lösning $y$. Vi vill hitta $C_1, C_2$. Tag en punkt $a\in I$ och lös systemet:

  \begin{equation*}
    \begin{gathered}
      \begin{rcases*}
        C_1y_1(a)+C_2y_2(a)=y(a)\\
        C_1y_{1}^{\prime}(a)+C_2y_{2}^{\prime}=y^{\prime}(a)
      \end{rcases*}
    \end{gathered}
  \end{equation*}
  \par\bigskip

  \noindent Skriv som:


  \begin{equation*}
    \begin{gathered}
      \begin{pmatrix}
        y_1(a)&y_2(a)\\
        y_1^{\prime}(a)&y_{2}^{\prime}(a)
      \end{pmatrix}
      \begin{pmatrix}
        C_1\\
        C_2
      \end{pmatrix}
      = \begin{pmatrix}y(a)\\y^{\prime}(a)\end{pmatrix}
    \end{gathered}
  \end{equation*}
  \par\bigskip

  \noindent Har en lösning om matrisens determinant är nollskilld. Gäller om $W(y_1,y_2)(a)\neq0$. Detta går att visa! Så systemet har en lösning.
  \par\bigskip
  \noindent Vi kan defninera en lösning $g= C_1y_1+C_2y_2$ (linjär kombination av lösningar är en lösning på samma initalvillkor), men vi har unikhet, alltså måste lösningen vara samma, dvs $y=g$
\end{prf}
\par\bigskip

\begin{theo}[Abels sats]{thm:abel}
  Om $y_1$ och $y_2$ är lösningar till $y^{\prime\prime}+p(x)y^{\prime}+q(x)y=0$ där $p,q$ är kontinuerliga på $I$. Då är deras Wronskian $W(y_1, y_2)(x)=Ce^{-\int p(x)dx}$ där $C$ är en konstant som ej beror på $x$. Antingen är $W(y_1, y_2)(x)=0$ $\forall x\in I$ eller $W(y_1, y_2)(x)\neq0 $ $\forall x\in I$
\end{theo}
\par\bigskip

\begin{prf}[Bevisidé för Abels sats]{thm:sketch}
  Derivera $W(y_1, y_2)$ med avseende på $x$. Då får man ett uttryck som innehåller $y_1, y_2$ och dess derivator. Använder man ODE:n så kan man visa att även $W$ uppfyller en linjär första ordningens ODE och den kan man lösa explicit.
\end{prf}





















