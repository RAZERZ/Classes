\section{Pertubation Theory}\par
\noindent This applies to another class of problems that is known (in a sense that we know how to solve it, we can find the solution); and we consider a new problem that is made of a known problem + \textit{a pertubation}:\par
\begin{center}
  Problem + $\varepsilon$ Problem$_2\qquad \varepsilon << 1$
\end{center}
\par\bigskip
\noindent\textbf{Example:} Planetary motion\par
\noindent If we consider a 2-body problem (one planet \& one star), this can be solved exactly\par
\noindent Consider now a 3-body problem, then this problem cannot be solved easily.
\begin{equation*}
  \begin{gathered}
    M_{\text{sun}} >> M_{p_1} M_{p_2}\\
    \underbrace{F_{Sp_1}+F_{Sp_2}}_{\text{2-body}}+\overbrace{F_{p_2p_1}}^{\text{$F_{p_2p_1}<< F_{Sp_{1,2}}$}}
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent\textbf{AnmÃ¤rkning:} Here $F_{Sp_i}$ denotes the gravitational pull from the sun to one planet.
\par\bigskip
\noindent In general, we apply pertubation theory to equation of the form $F(y,y^{\prime},y^{\prime\prime},\cdots,\varepsilon)=0$.\par
\noindent We look for a solution $y = y_0+y_1\varepsilon+y_2\varepsilon^2+y_3\varepsilon^3+\cdots$\par
\noindent We expect $y_0$ (leading term) to be the solution/approximation when $\varepsilon=0$ 
\par\bigskip
\noindent We may ask ourselves if the approximation converges to the solution.
\par\bigskip
\noindent\textbf{Example:}\par
\begin{equation*}
  \begin{gathered}
    \hat{y} = -y+\varepsilon y^2\qquad y(0) = 1
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent We try to do the easiest thing and plug in the approximation:
\begin{equation*}
  \begin{gathered}
    (\hat{y}_0+\varepsilon\hat{y}_1+\varepsilon^2\hat{y}_2+\cdots) = -(y_0+\varepsilon y_1+\varepsilon^2 y_2+\cdots)+\varepsilon(y_0+y_1\varepsilon+\cdots)^2
  \end{gathered}
\end{equation*}\par
\noindent Now we try to solve order by order (collect like terms and see which one equates):
\begin{equation*}
  \begin{gathered}
    \hat{y}_0 = -y_0\\
    y_0 = Ae^{-t}\qquad y_0 = e^{-t}\qquad\text{since our initial condition}\\
    \hat{y}_1 = -y_1+y_0^2=-y_1+e^{-2t}\\
    \hat{y}_1(0) = 0\qquad\text{since we already used our initial condition}\\
    y_1(t) = e^{-t}+Ae^{-2t}\Rightarrow y_1(t) = e^{-t}-e^{-2t}\\
    \hat{y}_2 = -y_2+2y_0y_1=-y_2+2e^{-t}(e^{-t}-e^{-2t})\\
    \hat{y}_2(0)\Rightarrow y_2(t) = e^{-t}-2e^{-2t}+e^{-3t}
  \end{gathered}
\end{equation*}\par
\noindent We have found the first three terms. This problem can be solved exactly, and we can see if our construction solves the equation or not:
\begin{equation*}
  \begin{gathered}
    y(t) = e^{-t}+\varepsilon(e^{-t}-e^{-2t})+\varepsilon^2(e^{-t}-2e^{-2t}+e^{-3t})+\cdots
  \end{gathered}
\end{equation*}\par
\noindent This is a case where regular pertubation works really well, since the explicit solution is given by:
\begin{equation*}
  \begin{gathered}
    y(t) = \dfrac{e^{-t}}{1-\varepsilon+\varepsilon e^{-t}} = \dfrac{e^{-t}}{1+\varepsilon(e^{-t}-1)}\\
    \sum_{n}x^n = \dfrac{1}{1-x}\Rightarrow e^{-t}(1-\varepsilon(e^{-t}-1)+\varepsilon^2(e^{-t}-1)^2+\cdots)
  \end{gathered}
\end{equation*}\par
\noindent This is not always the case, that it is the same solution. If we use the example from the last lecture (projectile problem), we get something different:
\begin{equation*}
  \begin{gathered}
    h^{\prime\prime} = \dfrac{-1}{(1+\varepsilon h)^2}\\
    \varepsilon = 0\Rightarrow h_0 = \dfrac{-t^2}{2}+t
  \end{gathered}
\end{equation*}\par
\noindent We try the same technique, suppose $h = h_0+\varepsilon h_1$:
\begin{equation*}
  \begin{gathered}
    (h^{\prime}_0+h^{\prime}_1\varepsilon)(1+\varepsilon(h_0+\varepsilon h_1))^2 = -1\\
  \end{gathered}
\end{equation*}\par
\noindent We collect like terms:
\begin{equation*}
  \begin{gathered}
    h_1^{\prime\prime}+2h^{\prime\prime}_0h_0=0\\
    h_1 = -(-1)\left(\dfrac{t^4}{4}+t^2-t^3\right)\\
    h^{\prime}_1 = \dfrac{t^5}{20}+\dfrac{t^3}{3}-\dfrac{t^4}{4}+C\qquad h^{\prime}_1(0) = 0\qquad h_1(0) = 0\\
    h_1 = \dfrac{t^6}{100}+\dfrac{t^4}{12}-\dfrac{t^5}{20}
  \end{gathered}
\end{equation*}\par
\noindent We have a polynomial in $t$ which is greater than the one in $h_0$, and an exponential in the other.
\par\bigskip
\noindent Well, in the terms $\varepsilon(e^{-t}+\cdots)$, the size is dominated by $\varepsilon$ even when $t$ grows, while in the polynomial no matter how small $\varepsilon$ we choose the polynomial can always grow bigger. So $h_0+\varepsilon h_1$, $h_1$ term grows too much. This does not mean that the term is wrong, but it may not have a meaning in the problem that we are considering. 
\par\bigskip
\noindent $h_1$ is growing faster than $h_0$ even though there is an $\varepsilon$ in front of it. Recall that $h_1$ is just a correction, because we are adding a term that is bigger than our first approximation. We are essentially not writing a function that is adding smaller and smaller terms. 
\par\bigskip
\noindent This method is called \textit{regular pertubation}, and sometimes it works and sometimes it does not. In the case when it does not, we have to try a different technique.\par
\noindent We consider a different problem:
\par\bigskip
\noindent\textbf{Example:} Duffin Equation
\begin{equation*}
  \begin{gathered}
    \hat{\hat{u}} + u+\varepsilon u^3 = 0\qquad t>0\\
    u(0) = 1\qquad \hat{u}(0) = 0
  \end{gathered}
\end{equation*}\par
\noindent In this case, we do not have an explicit formula for the solution. We can try to use regular pertubation and see if it has a meaning or not.
\begin{equation*}
  \begin{gathered}
    u = u_0+\varepsilon u_1\\
    \Rightarrow \hat{\hat{u}} + u_0 = 0\qquad u_0(0) = 1 \qquad \hat{u}_0(0)=0\\
    u_0(t) = A\cos(t)+B\sin(t)\\
    u_0(0) = 1\Rightarrow A = 1\\
    \hat{u}_0(0)= -\sin(0)+B\cos(0)=0\Rightarrow B = 0\\
    u_0 = \cos(t)
  \end{gathered}
\end{equation*}\par
\noindent Notice that for $u_0$, we have an oscillatory solution (since the trig-functions are periodic).
\par\bigskip
\noindent We collect like terms and equate them:
\begin{equation*}
  \begin{gathered}
    \hat{\hat{u}}_1+u_1+u^3_0=0\qquad u_1(0) = 0 \qquad\hat{u}_1(0) = 0\\
    \hat{\hat{u}}_1 = -u_1-\cos^3(t)\\
    \cos^3(t) = \left(\dfrac{e^{i\pi}+e^{-\pi}}{2}\right)^3 =  \dfrac{e^{3i\pi}+e^{-3i\pi}+3d^{2i\pi-i\pi}+3e^{i\pi-2i\pi}}{8}\\
    =\dfrac{1}{4}\cos(3t)+\dfrac{3}{4}\cos(t)\\
    \Rightarrow \hat{\hat{u}}_1+u_1 = \dfrac{1}{4}\cos(3t)+\dfrac{3}{4}\cos(t)\\
    u_1(0)=0 \qquad\hat{u}_1(0)=0\Rightarrow u_1(t) = A\cos(t)+B\sin(t)+C\cos(3t)+At\sin(t)+Bt\cos(t)
  \end{gathered}
\end{equation*}\par
\noindent Notice that since one particular solution already included $\cos(t)$, we add another set of $A\sin(t)+B\cos(t)$, but multiplied with $t$.\par
\noindent With respect to the initial conditions, we get:
\begin{equation*}
  \begin{gathered}
    u_1(t) = \dfrac{1}{32}(\cos(3t)-\cos(t))-\underbrace{\dfrac{3}{8}t\sin(t)}_{\text{Secular term}}
  \end{gathered}
\end{equation*}\par
\noindent The secular term might be a problem, for exmaple in this case we are interested in an oscillatory solution, so we expect a correction that gives us oscillatory approximation. But the $t$ term makes the correction explode when $t\to\infty$.\par
\noindent There is also another issue with this approximation. We can show that the solution to this equation is bounded, but with this solution it breaks when $t\to\infty$, so $u_0+\varepsilon u_1$ is not good. 
\par\bigskip
\begin{prf}[Exact solution is bounded]{}
  Consider $\hat{\hat{u}}+u+\varepsilon u^3=0$, and multiply with $\hat{u}$:
  \begin{equation*}
    \begin{gathered}
      \hat{u}\hat{\hat{u}}+\hat{u}u+\varepsilon\hat{u}u^3=0\\
      =\dfrac{d}{dt}\left(\dfrac{\hat{u}^2}{2}+\dfrac{u^2}{2}+\dfrac{\varepsilon u^4}{4}\right) = 0\Rightarrow \dfrac{\hat{u}^2}{2}+\dfrac{u^2}{2}+\dfrac{\varepsilon u^4}{4} = \text{Constant} = \dfrac{1}{2}+\dfrac{\varepsilon}{4}\\
      \Rightarrow u\text{ is bounded}
    \end{gathered}
  \end{equation*}
\end{prf}
\par\bigskip
\noindent Sometimes having small errors may not seem like a big issue, but these small errors may explode further down as $t\to\infty$
\par\bigskip
\subsection{Poincare-Lindstedt Method}\hfill\\
\par\bigskip
\noindent The idea is to do a rescaling, considering a pertubative correction of the frequencies of the oscillation.
\par\bigskip
\noindent We introduce a new variable (distorted time scale) $\tau = \omega t$ where $\omega = \omega_0+\omega_1\varepsilon+\omega_2\varepsilon^2+\cdots$.\par
\noindent As in the other case, $\omega_0$ is the leading term when $\varepsilon=0$, which in the previous example is 1.
\par\bigskip
\noindent We have to rewrite the equation according to the new time:
\begin{equation*}
  \begin{gathered}
    \dfrac{du}{dt} = \dfrac{du}{dt}\dfrac{dt}{d\tau} = \hat{u}\dfrac{1}{\omega}\\
    \Rightarrow \hat{u} =\omega u^{\prime}\qquad u^{\prime} = \dfrac{du}{d\tau}
  \end{gathered}
\end{equation*}\par
\noindent In the Duffin equation with the new variables we get:
\begin{equation*}
  \begin{gathered}
    \omega^2u^{\prime\prime}+u+\varepsilon u^3=0 \qquad u(0) \stackrel{\tau=0}{=} 1\qquad \dfrac{du}{d\tau}(0)=\dfrac{\hat{u}(0)}{\omega} = 0
  \end{gathered}
\end{equation*}\par
\noindent We now study this equation when $\tau >0$. Essentially what we do, the advantage in this expansion, is that we can kill the terms that in regular pertubation generates the problem terms (secular terms).\par
\noindent What we will do is choose $\omega_1$ such that it kills the secular terms. The procedure is the same as in regular pertubation:
\begin{equation*}
  \begin{gathered}
    (\omega_0+\omega_1\varepsilon)^2(u^{\prime\prime}_0+\varepsilon u^{\prime\prime}_1)+u_0+\varepsilon u_1+\varepsilon(u_0+u_1\varepsilon)^3=0
  \end{gathered}
\end{equation*}\par
\noindent Gather terms and equate:
\begin{equation*}
  \begin{gathered}
    w_0^2+u^{\prime\prime}_0+u_0=0\qquad u_0(0) =1\qquad u^{\prime}_0(0)=0\\
    u_0= \cos(\tau)\qquad w_0=1\\
    (1+2\omega_1\varepsilon+\omega_1^2\varepsilon^2)(u^{\prime\prime}_0+\varepsilon u^{\prime\prime}_1)+u_0+\varepsilon u_1+\varepsilon(u_0+u_1\varepsilon)^3=0\\
    \Rightarrow 2\omega_1 u^{\prime\prime}_0+u^{\prime\prime}_1+u_1+u_0^3=0\Rightarrow u^{\prime\prime}_1+u_1=-u_0^3-2\omega_1 u^{\prime\prime}_0 = -\cos^3(t)-2\omega_1-\cos(\tau)\\
    \Rightarrow \dfrac{1}{4}\cos(3\tau)+\dfrac{3}{4}\cos(\tau)+2\omega_1\cos(\tau)\\
    \Rightarrow \dfrac{1}{4}\cos(3\tau)+\left(2\omega_1-\dfrac{3}{4}\right)\cos(\tau)
  \end{gathered}
\end{equation*}\par
\noindent Notice that the last $\cos(\tau)$ is the generator of our secular term, so we choose $\omega_1$ so that $2\omega_1-\dfrac{3}{4}=0\Rightarrow \omega_1 = \dfrac{3}{8}$
\par\bigskip
\noindent What we now get is an approximate term $u_1$ that does not have a secular term, but just sine and cosine (preserving oscillation). We can also use some of the previous calculations, but without the secular term since we have removed it. 
\begin{equation*}
  \begin{gathered}
    u_1(\tau) = \dfrac{1}{32}\left(\cos(3\tau)-\cos(\tau)\right)\\
    u = \cos(\tau) + \dfrac{\varepsilon}{32}\left(\cos(3\tau)-\cos(\tau)\right)\\
    \tau = \omega t = (1+\dfrac{3}{8}\varepsilon)t
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent We have so far covered \textit{singular pertubation}. Let us look at an example when this method fails:
\par\bigskip
\noindent\textbf{Example:} $\varepsilon x^5+x-1=0\qquad 0<\varepsilon<<1$:
\begin{equation*}
  \begin{gathered}
    \varepsilon=0\qquad x=1\\
    x_0+\varepsilon x_1+\varepsilon^2x_2+\cdots\\
    x_0=1
  \end{gathered}
\end{equation*}\par
\noindent From this equation we expect 5 different solutions since it is a polynomial of order 5.\par
\noindent The issue we have here is that the $\varepsilon$ is in front of the term of highest order.
\par\bigskip
\subsection{Dominant Balancing method}\hfill\\

Another example could therefore be $\varepsilon y^{\prime\prime}+y^{\prime}+y=0$.
\par\bigskip
\noindent The strategy is to look for a scaling such that the leading term can remain big even though we multiply by $\varepsilon$. We can do this by defining a new variable $x = \dfrac{y}{f(\varepsilon)}$ that allows us to describe problem when the term that we are removing is not small anymore.
\par\bigskip
\noindent We solve using \textit{dominant balancing}. \par
\noindent\textit{Case:} Say $\varepsilon x^5 = O(X)$, then $\varepsilon x^4 = (1)$ and $x = O\left(\dfrac{1}{\sqrt[4]{\varepsilon}}\right)$\par
\noindent We then get:
\begin{equation*}
  \begin{gathered}
    \varepsilon x^5 = \varepsilon O\left(\left(\dfrac{1}{\sqrt[4]{\varepsilon}}\right)^4\right) = O\left(\varepsilon^{1-\dfrac{5}{4}}\right) = O\left(\varepsilon^{-\dfrac{1}{4}}\right)
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent With this choice, are these terms bigger than the remaining one? In this case the remaining one is 1, so it is true that when $\varepsilon<<1$ then $\dfrac{1}{\sqrt[4]{\varepsilon}}>>1$
\par\bigskip
\noindent\textit{Case:} Say $\varepsilon x^5 = (1)$, then $x = O\left(\dfrac{1}{\sqrt[5]{\varepsilon}}\right)$. So for the second term (that is $x$), we get
\begin{equation*}
  \begin{gathered}
    x = O\left(\dfrac{1}{\sqrt[5]{\varepsilon}}\right)
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent We see that this is not a good choice because the remaining term $x = O\left(\dfrac{1}{\sqrt[5]{\varepsilon}}\right)>>1$ when $\varepsilon\to0$.\par
\noindent This is a problem  because we want the leading term to be the bigger one.
\par\bigskip
\noindent It is this reasoning that we use when we determine $f(\varepsilon)$.\par
\noindent Since we saw that the choice $x = \dfrac{y}{\sqrt[4]{\varepsilon}}\Rightarrow f(\varepsilon) = \varepsilon^{-\dfrac{1}{4}}$, we substitute this variable in the equation and try to solve for $y$:
\begin{equation*}
  \begin{gathered}
    \dfrac{\varepsilon y^5}{(\sqrt[4]{\varepsilon})^5}+\dfrac{y}{\sqrt[4]{\varepsilon}} - 1=0\\
    y^5\varepsilon^{1-\dfrac{5}{4}}+y\varepsilon^{-\dfrac{1}{4}}-1=0\\
    \Rightarrow y^5 +y-\varepsilon^{\dfrac{1}{4}} = 0
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent Now $\varepsilon$ is not in the term of the highest order and we can solve using regular pertubation.\par
\noindent We solve the equation for $\varepsilon=0$:
\begin{equation*}
  \begin{gathered}
    y^5+y=0\Lrarr y(y^4+1) = 0
  \end{gathered}
\end{equation*}\par
\noindent One solution is $y=0$, but this is a false root because of our initial conditions (\textbf{CHECK}). The other 4 solutions are given by the roots of unity for $y^4+1=0$:
\begin{equation*}
  \begin{gathered}
    y^4 = -1 = e^{i\pi}\\
    y_{1,2,3,4} = e^{\dfrac{i\pi+2n\pi}{4}}\qquad n = 0,1,2,3\\
    \Rightarrow y = y_0+\varepsilon y_1+\varepsilon^2 y_2+\cdots\qquad\text{leading term $y_0$ are the roots } y_n
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent Going back to our original variable $x = \dfrac{y}{\sqrt[4]{\varepsilon}}$ has leading order terms $\dfrac{y_n}{\sqrt[4]{\varepsilon}}$.
\par\bigskip
\noindent This is for the leading order, you can of course compute for the other terms.
\par\bigskip
\noindent\textbf{Examples:}\par
\begin{itemize}
  \item $\varepsilon x^2+2x+1=0$
  \item $\varepsilon x^4+\varepsilon x^3-x^2+2x-1=0$
\end{itemize}\par
\noindent Try to understand which are the leading orders of the approximated solutions.\par
\noindent (\textbf{DO THESE})
\par\bigskip
\noindent\textbf{Example:}\par
\begin{itemize}
  \item $\varepsilon y^{\prime\prime}+(1+\varepsilon)y^{\prime}+y=0$
  \item $y(0) = 0$
  \item $y(1) = 1$
\end{itemize}
\par\bigskip
\noindent Here the problem is a bit different, due to the initial conditions, when $\varepsilon=0$ the equation cannot be solved since
\begin{equation*}
  \begin{gathered}
    \varepsilon=0\Rightarrow y^{\prime}+y=0\qquad y^{\prime} = -y\qquad y(x) = Ae^{-x}\\
    y(0) = A = 0 \Leftarrow \text{ not a solution}
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent We can compute the solution exactly, this will tell us what the problem is when approaching this in pertubative approach:
\begin{equation*}
  \begin{gathered}
    \varepsilon m^2+(1+\varepsilon)m+1=0\\
    m_{1,2} = \dfrac{-(1+e)\pm\sqrt{(1+\varepsilon)^2-4\varepsilon}}{2\varepsilon}\\
    m_1 = -1\qquad m_2 = -\dfrac{1}{\varepsilon}\\
    \Rightarrow y(x) = C_1e^{-x}+C_2e^{-\dfrac{x}{\varepsilon}}\\
    y(0) = C_1+C_2 = 0\Rightarrow C_1 = -C_2\\
    y(1) = C_2\left(e^{-\dfrac{1}{\varepsilon}}-e^{-1}\right) = 1\Lrarr C_2 = \dfrac{1}{\left(e^{-\dfrac{1}{\varepsilon}}-e^{-1}\right)}\\
    y(x) = \dfrac{1}{\left(e^{-(1/\varepsilon)}-e^{-1}\right)}\cdot\left(e^{-(x/\varepsilon)}-e^{-x}\right)
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent The problem is the size of the term $\varepsilon y^{\prime\prime}$, even if $\varepsilon$ is very small the term can be very big.
\par\bigskip
\noindent Using the exact solution we can compute the second derivative:
\begin{equation*}
  \begin{gathered}
    y^{\prime\prime} = \dfrac{1}{e^{-(1/\varepsilon)}-e^{-1}}\left(e^{-x}-\dfrac{1}{\varepsilon^2}e^{-(x/\varepsilon)}\right)
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent If we look at $y^{\prime\prime}(x)$ when $x\to0$:
\begin{equation*}
  \begin{gathered}
    \dfrac{1}{e^{-(1/\varepsilon)}-e^{-1}}\left(C-\dfrac{1}{\varepsilon^2}D\right)
  \end{gathered}
\end{equation*}\par
\noindent So $\varepsilon y^{\prime\prime}(x) = O\left(\dfrac{1}{\varepsilon}\right)$ which is not small when $\varepsilon=0$ \par
\noindent But when $x = O(1)\qquad x>>1$:
\begin{equation*}
  \begin{gathered}
    y^{\prime\prime}(x) = 0
  \end{gathered}
\end{equation*}\par
\noindent So in fact, $\varepsilon y^{\prime\prime}$ is small when $x$ grows.
\par\bigskip
\noindent We can therefore say that our solution $y = Ae^{-x}$ is valid as long as $x$ is not close to 0 since we have $\varepsilon y^{\prime\prime} = O(\varepsilon)$ and we can use regular pertubation.\par
\noindent Using $y(1) = 1$ (and not 0, since we want $x$ to be as far away from 0 as we can) we have:
\begin{equation*}
  \begin{gathered}
    y_{\text{outer}}(x) = e\cdot e^{-x} = e^{1-x}
  \end{gathered}
\end{equation*}\par
\noindent Where $y_{\text{outer}}$ denotes the outer domain ($x = O(1)$).  This is only the leading order of the approximation (we are keeping the solution when $\varepsilon=0$).
\par\bigskip
\noindent Just as we did with the polynomial, in order to fully solve this we introduce a rescaling to our problem to consider when $\varepsilon y^{\prime\prime}$ is small:
\begin{equation*}
  \begin{gathered}
    \tau = \dfrac{x}{f(\varepsilon)}\\
    y^{\prime} = \dfrac{dy}{dx} = \dfrac{dy}{d\tau}\dfrac{d\tau}{dx} = \hat{y}\dfrac{1}{f(\varepsilon)}
  \end{gathered}
\end{equation*}\par
\noindent Inserting this in the equation gives us:
\begin{equation*}
  \begin{gathered}
    \varepsilon\dfrac{\hat{\hat{y}}}{f(\varepsilon)^2}+(1+\varepsilon)\dfrac{\hat{y}}{f(\varepsilon)}+y=0
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent Now we compare cases:\par
\textit{Case 1:}
\begin{equation*}
  \begin{gathered}
    \dfrac{\varepsilon}{f(\varepsilon)^2} = O\left(\dfrac{1+\varepsilon}{f(\varepsilon)}\right)\Rightarrow f(\varepsilon) = O\left(\dfrac{\varepsilon}{1+\varepsilon}\right) = O(\varepsilon)\\
    \begin{cases*}
      \dfrac{\varepsilon\hat{\hat{y}}}{\varepsilon^2} = \dfrac{\hat{\hat{y}}}{\varepsilon}\\
      \dfrac{1+\varepsilon}{\varepsilon}\hat{y}\to O\left(\dfrac{1}{\varepsilon}\right)\\
      y\text{ is } O(1)
    \end{cases*}\\
    \dfrac{1}{\varepsilon} >> 1
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent We can check that choosing:
\begin{equation*}
  \begin{gathered}
    \dfrac{\varepsilon}{f(\varepsilon)^2} = O(1)\qquad f(\varepsilon) = O(\sqrt{\varepsilon})\\
    \begin{cases*}
      \dfrac{\varepsilon}{f(\varepsilon)^2}\hat{\hat{y}} = O(1)\\
      \dfrac{1+\varepsilon}{\sqrt{\varepsilon}} = O\left(\dfrac{1}{\sqrt{\varepsilon}}\right)
    \end{cases*}
  \end{gathered}
\end{equation*}\par
\noindent In this case we see that the term in front of $\hat{y}$ is bigger than the one in front of $\hat{\hat{y}}$ 
\par\bigskip
\noindent The equation with the rescaling $\tau = \dfrac{x}{\varepsilon}$ becomes:
\begin{equation*}
  \begin{gathered}
    \dfrac{\varepsilon}{\varepsilon^2}\hat{\hat{y}} + \dfrac{1+\varepsilon}{\varepsilon}\hat{y} + y = 0\\
    \hat{\hat{y}}+(1+\varepsilon)\hat{y}+\varepsilon y = 0
  \end{gathered}
\end{equation*}\par
\noindent We solve using regular pertubation:
\begin{equation*}
  \begin{gathered}
    \varepsilon = 0\qquad \hat{\hat{y}}+\hat{y} = 0\qquad m^2+m=0\Lrarr m(m+1) = 0\\
    y_{\text{inner}}(\tau) = A+Ae^{-\tau} = A(1+e^{-\tau})
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent We have a set of equations to describe our solutions, one given by our outer approximation and one for our inner:
\par\bigskip
$
\begin{cases*}
  y_{\text{outer}}(x) = e^{1-x}\\
  y_{\text{inner}} = A(1+e^{-(x/\varepsilon)})\qquad x= O(\varepsilon)
\end{cases*}$
\par\bigskip
\noindent We still have the parameter $A$. We can merge the two solutions in the part of the domain that is hared, for exmaple where $x\approx O(\sqrt{\varepsilon})\qquad \varepsilon<\sqrt{\varepsilon}<1$\par
\noindent We impose that when $x\cong O(\sqrt{\varepsilon})$, the limits of the two functions is the same.
\par\bigskip
\noindent We can define an auxillary variable $\eta = \dfrac{x}{\sqrt{\varepsilon}}$:
\begin{equation*}
  \begin{gathered}
    \lim_{\varepsilon\to0^+}y_{\text{outer}}(\eta\sqrt{\varepsilon}) = \lim_{\varepsilon\to0^+}y_{\text{inner}}(\eta\sqrt{\varepsilon})\\
    \lim_{\varepsilon\to0^+}e^{1-\eta\sqrt{\varepsilon}} = e\\
    \lim_{\varepsilon\to0^+}A\left(1-e^{-(\eta/\sqrt{\varepsilon})}\right) = A\Rightarrow A = e
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent You can also write this as one singular function:
\begin{equation*}
  \begin{gathered}
    y = y_{\text{outer}} + y_{\text{inner}} - \underbrace{\text{common limit}}_{\text{$e$}}\\
    \Rightarrow e^{1-x}+e^{1-(x/\varepsilon)}
  \end{gathered}
\end{equation*}
