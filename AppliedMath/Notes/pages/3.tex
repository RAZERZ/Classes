\section{Calculus of Variations}
\noindent From last time (\textbf{READ}):
\begin{equation*}
  \begin{gathered}
    \int_{a}^{b}L(x,y,y^{\prime})dx\qquad y(a) = A\qquad y(b) = B
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent An extremal satisifies Euler-Lagranges equation:
\begin{equation*}
  \begin{gathered}
    L_y -\dfrac{d}{dx}(L_{y^{\prime}}) = 0
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent One generalisation of this formula can be obtainedwhen $L = L(x,y,y^{\prime}, y^{\prime\prime})$. In this case we have to assume some regularity for $y$, that is $y\in C^4[a,b]$, and two other initial condition for $y^{\prime}$. 
\par\bigskip
\noindent We compute the derivative of the functional  $\delta J(y; v) = \dfrac{d}{d\varepsilon}J(y+\varepsilon v)|_{\varepsilon=0}$\par
\noindent We want $y+\varepsilon v$ to be an admissable function, so this means that $ v(a) =  v(b)=0$ and $ v^{\prime}(a)= v^{\prime}(b)=0$
\par\bigskip
\noindent Using this when trying to compute the derivative of the functional:
\begin{equation*}
  \begin{gathered}
    \dfrac{d}{d\varepsilon}\int_{a}^{b}L(x,y+\varepsilon v,y^{\prime}+\varepsilon v^{\prime},y^{\prime\prime}+\varepsilon v^{\prime\prime})dx|_{\varepsilon=0}\\
    \Rightarrow \int_{a}^{b}L_y v+L_{y^{\prime}} v^{\prime}+L_{y^{\prime\prime}} v^{\prime\prime}dx
  \end{gathered}
\end{equation*}\par
\noindent We solve this by integration by parts:
\begin{equation*}
  \begin{gathered}
    \int_{a}^{b}(L_y-\dfrac{d}{dx}L_{y^{\prime}}) v dx +\int_{a}^{b}L_{y^{\prime\prime}} v^{\prime\prime}dx  =  v^{\prime}L_{y^{\prime\prime}}|_a^b-\int_{a}^{b} v^{\prime}\dfrac{d}{dx}(L_{y^{\prime\prime}})dx
  \end{gathered}
\end{equation*}\par
\noindent By our initial conditions, $ v^{\prime}L_{y^{\prime\prime}}|_a^b = 0$:
\begin{equation*}
  \begin{gathered}
    - v\left(\dfrac{d}{dx}L_{y^{\prime\prime}}\right)_a^b+\int_{a}^{b} v\left(\dfrac{d^2}{dx^2}L_{y^{\prime\prime}}\right)dx\\
    =\int_{a}^{b}L_y-\dfrac{d}{dx}L_{y^{\prime}}+\dfrac{d^2}{dx^2}L_{y^{\prime\prime}} v(x)dx = 0\qquad\forall v
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent The condition here becomes:
\begin{equation*}
  \begin{gathered}
    L_y-\dfrac{d}{dx}L_{y^{\prime}}+\dfrac{d^2}{dx^2}L_{y^{\prime\prime}}=0
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent In this equation we will have the 4th derivative w.r.t $y$, which is why we need $y\in C^4[a,b]$
\par\bigskip
\noindent As an exercise, try to generalise the formula:\par
if $L = L(x,y,y^{\prime},\cdots, y^{(n)})\Rightarrow$ the extremals satisfy:
\begin{equation*}
  \begin{gathered}
    L_y+\sum_{k=1}^{n}(-1)^k\dfrac{d^k}{dx^k}L_{y^{(k)}}=0
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent The reason we have a plus and minus is because whenever we integrate by parts we will get a plus and next time a minus etc...
\par\bigskip
\noindent\textbf{Exercicse:} Show that if $L$ does not depend on $y$ ($L = L(x,y^{\prime}, y^{\prime\prime})$), then $L_{y^{\prime}}-\dfrac{d}{dx}L_{y^{\prime\prime}}=C$ (some constant)
\par\bigskip
\noindent\textbf{Exercicse:} If $L$ does not depend on $x$, show that $L-y^{\prime}(L_y^{\prime}-\dfrac{d}{dx}L_{y^{\prime\prime}})-y^{\prime\prime}L_{y^{\prime\prime}} = C$ (some constant)
\par\bigskip
\noindent Another generalisation occurs when we have $L = L(x,y_1,y_2,y_1^{\prime},y_2^{\prime})dx$ with initial values:
\begin{equation*}
  \begin{gathered}
    y_1(a) = A_1\qquad y_1(b) = B_1\\
    y_2(a) = A_2\qquad y_2(b) = B_2
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent Proceeding with the same strategy as before, we compute the derivative. Starting by imposing $\delta J(y; v)=0$:
\begin{equation*}
  \begin{gathered}
    \int_{a}^{b}\dfrac{d}{d\varepsilon}L(x,y_1+\varepsilon v_1,y_2+\varepsilon v_2,y_1^{\prime}+\varepsilon v_1^{\prime},y_2^{\prime}+\varepsilon v_2^{\prime})dx|_{\varepsilon=0}=0
  \end{gathered}
\end{equation*}\par
\noindent In this case we have that $ v_1, v_2(a) = 0= v_1, v_2(b)$
\begin{equation*}
  \begin{gathered}
    \int_{a}^{b}\left(L_{y_1}-\dfrac{d}{dx}L_{y_1}\right) v_1(x)dx+\int_{a}^{b}\left(L_{y_2}-\dfrac{d}{dx}L_{y_2}\right)dx=0\qquad\forall v_1,v_2
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent The trick here is that since this equation has to be true for all $v_1, v_2$, so in particular $v_2=0$. This yields:
\begin{equation*}
  \begin{gathered}
    \int_{a}^{b}\left(L_{y_1}-\dfrac{d}{dx}L_{y_1}\right)v_1(x) dx = 0\qquad\forall v_1\Rightarrow L_{y_1}-\dfrac{d}{dx}L_{y_1^{\prime}}= 0
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent and so 
\begin{equation*}
  \begin{gathered}
    \int_{a}^{b}L_{y_2}-\dfrac{d}{dx}L_{y_2^{\prime}}v_2(x)dx = 0\qquad\forall v_2\\
    \begin{cases*}
      L_{y_1} -\dfrac{d}{dx}L_{y_1^{\prime}} = 0\\
      L_{y_2} -\dfrac{d}{dx}L_{y_2^{\prime}} = 0
    \end{cases*}
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent\textbf{Exercicse:} Show that if $L = L(y_i; y_i^{\prime})$ (for $i=1,\cdots, n$), then
\begin{equation*}
  \begin{gathered}
    L-\sum_{i=1}^{n}y_i^{\prime}L_{y_i^{\prime}} = C\qquad\text{if } y_i\text{ satisfies the Euler-Lagrange equations}
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent Let us see what happens if we leave one of the end-boundary conditions unsatisfied, how long will we come in our computation. This is a type of generalisation where the boundary can be free (aka a \textit{free end-point problem}):
\begin{equation*}
  \begin{gathered}
    J(y) = \int_{a}^{b}L(x,y,y^{\prime})dx\qquad y(a) = A\qquad y(b)\text{ is free}
  \end{gathered}
\end{equation*}\par
\noindent We look for extremals. In all our previous computation, to have admissable functions, we took $v(a) = v(b) = 0$. When we looked at the derivative $y+\varepsilon v$, and for it to be admissable we have $y(a)+\varepsilon v(a) = A$, and $A+\varepsilon v(a)=A\Rightarrow v(a) = 0$.\par
\noindent This condition is not needed anymore in $v(b)$ because we are assuming that $y(b)+\varepsilon v(b)$ is free.
%\begin{equation*}
  %\begin{gathered}
    %\dfrac{d}{d\varepsilon}\int_{a}^{b}L(x,y+\varepsilon v,y^{\prime}+\varepsilon v^{\prime})dx|_{\varepsilon=0} = \int_{a}^{b}L_yv+L_{y_^{\prime}}v^{\prime}dx = \int_{a}^{b}(L_y-\dfrac{d}{dx}L_{y^{\prime}})v(x)dx+\underbrace{v(x)L_{y^{\prime}}|_a^b}_{\text{$\neq0$}}\\
    %=\int_{a}^{b}L_yv+L_{y_^{\prime}}v^{\prime}dx+v(b)L_{y^{\prime}}(b,y(b),y^{\prime}(b))=0
  %\end{gathered}
%\end{equation*}
\par\bigskip
\noindent If that term is 0 $\forall v$, it must be 0 for $v(b) = 0$:
\begin{equation*}
  \begin{gathered}
    L_y-\dfrac{d}{dx}L_{y^{\prime}} = 0
  \end{gathered}
\end{equation*}\par
\noindent If $v(b)\neq0$, then $v(b)L_{y^{\prime}}(b,y(b), y^{\prime}(b))=0$, and in that case:
\begin{equation*}
  \begin{gathered}
    \begin{cases*}
      L_y-\dfrac{d}{dx}L_{y^{\prime}} = 0\\
      L_{y^{\prime}}(b,y(b),y^{\prime}(b)) = 0
    \end{cases*}
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent\textbf{Exercicse:}
\begin{equation*}
  \begin{gathered}
    J(y) = \int_{0}^{1}(y^{\prime2}+y^2)dx\qquad y(0) = 1\qquad y(1) = \text{ free}
  \end{gathered}
\end{equation*}\par
\noindent Find extremals, so solve this equation
\begin{equation*}
  \begin{gathered}
    L_y -\dfrac{d}{dx}L_{y^{\prime}} = 0\\
    2y -\dfrac{d}{dx}(2y^{\prime}) = 0\\
    2y-2y^{\prime\prime}= 0\\
    y^{\prime\prime}-y=0\qquad y(x) = Ae^{-x}+Be^x\qquad y(0) = A+B = 1\Rightarrow A = 1-B\\
    y(x) = e^{-x}+B(e^x-e^{-x})\\
    L_{y^{\prime}} = (1,y(1), y^{\prime}(1)) = 0\qquad L_{y^{\prime}} = 2y^{\prime}\Rightarrow y^{\prime}(1) = 0\\
    y^{\prime}(x) = -e^{-x}+B(e^x+e^{-x})\Rightarrow y^{\prime}(1) = -e^{-1}+B(e+e^{-1}) = 0\\
    \Rightarrow B = \dfrac{1}{e}\dfrac{e}{e^2+1} = \dfrac{1}{e^2+1}
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent Another kind of exercise that can be computed with functionals is minimizing path distances.
\par\bigskip
\noindent\textbf{Exercicse:} Find the extremal paths that connect two points on a plane. This problem is equivalent to finding extremals to the functional $J(y) = \int_{a}^{b}\sqrt{1+y^{\prime}(x)^2}dx$ and $y(0) = a$, $y(1) = b$. Show that the solution is a line.
\par\bigskip
\noindent\textbf{Exercicse:} Find the extremal paths connecting two points on a cylinder.\par
\noindent Firstly, we switch to cylindrical coordinates: $(x,y,z) = (R\cos(\theta), R\sin(\theta), z)$ where $R$ is the radius (for simplicity, we set $R = 1$)
\begin{equation*}
  \begin{gathered}
    ds = \sqrt{dx^2+dy^2+dz^2}\qquad dx = -\sin(\theta)d\theta\qquad y = \cos(\theta)d\theta\\
    \Rightarrow ds = \sqrt{\sin^2(\theta)d\theta^2+\cos^2(\theta)d\theta^2+dz^2} = \sqrt{d\theta^2+dz^2} = d\theta\sqrt{1+\left(\dfrac{dz}{d\theta}\right)^2}\\
    S = \int_{P_1}^{P_1}ds=\int_{\theta_1}^{\theta_2}\sqrt{1+z^{\prime}(\theta)^2}d\theta
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent We now want to study the extremals with this functional:
\begin{equation*}
  \begin{gathered}
    L = L(z^{\prime}) = \sqrt{1+z^{\prime2}(\theta)^2}d\theta
  \end{gathered}
\end{equation*}\par
\noindent By the Euler-Lagrange equation:
\begin{equation*}
  \begin{gathered}
    L_z-\dfrac{d}{dx}L_{z^{\prime}} = 0\qquad L_{z^{\prime}} = C\qquad\dfrac{1}{2\sqrt{1+z^{\prime2}(\theta)}}\cdot2z^{\prime}(\theta) = C\\
    z^{\prime2} = C^2(1+z^{\prime2})\qquad z^{\prime2}(1-C^2) = C^2\Rightarrow z^{\prime2} = \dfrac{C^2}{(1-C^2)}\\
    z^{\prime} = K\text{ say for example } \dfrac{C}{\sqrt{1-C^2}}\\
    \Rightarrow z(\theta) = \theta K+aÂ§
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent\textbf{Exercicse:} Find the extremal paths connecting two points on a sphere. (You can use the radius 1 to help ya).
\par\bigskip
\noindent\textbf{Exercicse:} Consider the surface generated by a rotation around the $x$-axis of a curve $y(x)$. Can we find extremals?
\par\bigskip
\subsection{Hamiltons Principal}\hfill\\\par
\noindent Usually a system is described by a set of equations, and you want to know the evolution of the system given an initial condition.
\par\bigskip
\noindent\textbf{Example}: Newtons law
\begin{equation*}
  \begin{gathered}
    F = ma = mv^{\prime\prime}
  \end{gathered}
\end{equation*}\par
\noindent This law can be deduced through a variational principle. To do so, we need to define a specific functional. 
\par\bigskip
\noindent A mechanical system evolves in such a way that if we define the functional $\int (K-V)dt$ where $K$ is the kinetic energy and $V$ is the potential energy, the functional is stationary.\par
\noindent If we have a system we can compute the kinetic and the potential energy, and we define something called the Lagrangian $\mathcal{L} = K-V$, then we can study the integral:
\begin{equation*}
  \begin{gathered}
    \int_{t_0}^{t_1}\mathcal{L}(t,y,y^{\prime})dt
  \end{gathered}
\end{equation*}\par
\noindent Then the system evolves from $y(t_0)$ to $y(t_1)$ along a path $y(t)$ that is an extremal for the functional. So it means that $y$ satisfies Euler-Lagrange equation.\par
\noindent If we write down the Euler-Lagrange equation for these conditions, we will get something equivalent to Newtons Law.\par
\begin{itemize}
  \item Kinetic energy $ = \dfrac{1}{2}m\hat{x}^2$
  \item Potential energy $ = V(x)$
  \item Lagrangian $\mathcal{L}(x,\hat{x}) = \dfrac{1}{2}m\hat{x}^2-V(x)$
\end{itemize}
\begin{equation*}
  \begin{gathered}
    \Rightarrow \mathcal{L}_x-\dfrac{d}{dx}\left(\mathcal{L}_{\hat{x}}\right) = -V^{\prime}(x)-\dfrac{d}{dt}\left(m\hat{x}\right) = 0\\
    -V^{\prime}(x) = m\hat{\hat{x}} = F(x)
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent Another thing that is useful when studying these types of systems is to introduce \textit{Hamiltonian formalisms}.\par
\noindent We have seen that Euler-Lagrange equation define an ODE of second order. What we want to do here is to introduce a new formalism that allows us to deal with first order ODE. %introduce another of coordinates such that our ODE becomes a first order ODE. 
\par\bigskip
\noindent We consider the funcitonal:
\begin{equation*}
  \begin{gathered}
    J(y) = \int_{a}^{b}L(t,y,y^{\prime}) dt
  \end{gathered}
\end{equation*}\par
\noindent We define a new variable $p = \dfrac{\partial L(t,y,y^{\prime})}{\partial y^{\prime}} = L_{y^{\prime}}(t,y,y^{\prime})$ which we call canonical momentum.\par
\noindent We suppose that $L_{y^{\prime}}$ is regular enough for us to invert it in the following manner:
\begin{equation*}
  \begin{gathered}
    y^{\prime} = \Phi(t,p,y)\qquad L_{y^{\prime}y^{\prime}}\neq0\text{ can be a condition for the invertibility}
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent We define a new function (that is called the Hamiltonian):
\begin{equation*}
  \begin{gathered}
    H(t, y, p) = -L(t,y,\Phi(t,p,y)) + \Phi(t,p,y)\cdot p
  \end{gathered}
\end{equation*}\par
\noindent Now we look at the equations satisified by $\dfrac{\partial H}{\partial  y}, \dfrac{\partial H}{\partial  p}$:
\begin{equation*}
  \begin{gathered}
    \dfrac{\partial  H}{\partial  y} = -L_y-L_{y^{\prime}}\cdot\Phi_y+\Phi_y\cdot p = -L_y = \dfrac{-}{dt}L_{y^{\prime}} = -\dfrac{d}{dt}p = -\hat{p}\\
    \dfrac{\partial H}{\partial p} = -L_{y^{\prime}}\Phi_p+\Phi_pp+\Phi(t,p,y) = y^{\prime}
  \end{gathered}
\end{equation*}\par
\noindent Now we have $p,y$ on first order form in this new formalism\par
$
\begin{cases*}
  \hat{p} = -\dfrac{\partial H}{\partial y}\\
  \hat{y} = \dfrac{\partial H }{\partial  p}
\end{cases*}$. If we had $\mathcal{L}(t,y_1,\cdots,y_n, y_1^{\prime},\cdots,y_n^{\prime})$, and so extremals satisfy Euler-Lagrange equations $L_{y_i}-\dfrac{d}{dt}L_{y^{\prime}} = 0$ ,\par
\noindent With this procedure we would reduce to first order ODE. 
\par\bigskip
\noindent For example if we look at this Lagrangian, $\mathcal{L}(x,\hat{x}) = \dfrac{1}{2}m\hat{x}^2-V(x)$, we need to define $p = L_{\hat{x}} = m\hat{x}$.\par
\noindent Next step is to define $\Phi$, that is inverting $p\Rightarrow \hat{x} = \dfrac{p}{m}$\par
\noindent Last step is to substitute this:
\begin{equation*}
  \begin{gathered}
    H(x,p) = -L\left(x, \dfrac{p}{m}\right) + \dfrac{p}{m}p = -\dfrac{1}{2}m\dfrac{p^2}{m^2}+V(x)+\underbrace{\dfrac{p^2}{m}}_{\text{$p\Phi=m\hat{x}^2=2K(\hat{x})$}}\\
    H(x,p )= \dfrac{p^2}{2m}+V(x)\\
    \text{Hamilton equations = }
    \begin{cases*}
      \hat{p} = -\dfrac{\partial H}{\partial x} = -V^{\prime}(x)\\
      \hat{x} = \dfrac{\partial  H }{\partial  p} = \dfrac{p}{m}
    \end{cases*}
  \end{gathered}
\end{equation*}\par
\noindent In this set of equations we see that if both are satisfied and tried to compute the second derviative $\hat{\hat{x}}$, this would be the same as:
\begin{equation*}
  \begin{gathered}
    \hat{\hat{x}} = \dfrac{\hat{p}}{m} = \dfrac{-V^{\prime}(x)}{m}
  \end{gathered}
\end{equation*}\par
\noindent This is the same as Euler-Lagrange for the Lagrangian, or the Newton laws.
\par\bigskip
\noindent If the Hamiltonian does not depened explicitly on time, then it is constant:
\begin{equation*}
  \begin{gathered}
    \dfrac{dH}{dt}(x,p) = \dfrac{\partial H}{\partial x}\hat{x}+\dfrac{\partial H}{\partial p}\hat{p}
  \end{gathered}
\end{equation*}\par
\noindent Using the Hamilton equation here, we get:
\begin{equation*}
  \begin{gathered}
    =-\hat{p}\hat{x}+\hat{x}\hat{p} = 0\\
    H(x,p) = C
  \end{gathered}
\end{equation*}\par
\noindent In fact, $H(x,p)$ represents the total energy of the system, so it makes sense that it is a constant since the total energy does not change ($H = K+V$), but the quotient of does.
\par\bigskip
\noindent If $H = H(t,x,p)$ ($H$ depends on time):
\begin{equation*}
  \begin{gathered}
    \dfrac{dH}{dt} = \dfrac{\partial  H }{\partial t}
  \end{gathered}
\end{equation*}\par
\noindent And we can also show that $\dfrac{\partial  H}{\partial t} = -\dfrac{\partial L}{\partial t}$:
\begin{equation*}
  \begin{gathered}
    \dfrac{dH}{dt} = -\dfrac{dL}{dt}+\dfrac{d}{dt}(\Phi p)\\
    \dfrac{\partial H}{\partial t} = \dfrac{-\partial L}{\partial t}-\dfrac{\partial L}{\partial y}\dfrac{d}{dt}y-\dfrac{\partial L}{\partial y}\dfrac{d}{dt}(\Phi)+\left(\dfrac{d}{dt}\Phi\right)p+\Phi\cdot\hat{p}
  \end{gathered}
\end{equation*}\par
\noindent Recall that $p = L_{y^{\prime}}$, so:
\begin{equation*}
  \begin{gathered}
    = -\dfrac{\partial L}{\partial t}-\dfrac{\partial L}{\partial y}\hat{y}+\Phi\hat{p} = -\dfrac{\partial L}{\partial t}-\dfrac{\partial L}{\partial y}\Phi+\Phi\left(\dfrac{d}{dt}L_{y^{\prime}}\right)\\
    =\dfrac{\partial L}{\partial t}+\Phi\underbrace{\left(\dfrac{d}{dt}L_{y^{\prime}}-L_y\right)}_{\text{E-L eq. = 0}} = -\dfrac{\partial L}{\partial t}
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent\textbf{Example:} Pendulum on a plane, want to find equation of motion using the Hamiltonian principle, so we try to write the Lagrangian for this problem and study the stationary solution.
\begin{equation*}
  \begin{gathered}
    \mathcal{L} = K-V
  \end{gathered}
\end{equation*}\par
\noindent We can express the Kinetic energy as $K(\hat{\theta}) = \dfrac{1}{2}m(l\hat{\theta})^2$. The length of the arc is $l\theta$.\par
\noindent The potential is given by a function of $\theta$:
\begin{equation*}
  \begin{gathered}
    V(\theta) = mgh = mg(l-l\cos(\theta))\\
    \mathcal{L}(\theta,\hat{\theta}) = \dfrac{1}{2}ml^2\hat{\theta}Ã2-mgl+mgl\cos(\theta)
  \end{gathered}
\end{equation*}\par
\noindent Now we use Hamilton principle, that states that the motion is stationary for the functional:
\begin{equation*}
  \begin{gathered}
    \int\mathcal{L}(\theta,\hat{\theta})dt
  \end{gathered}
\end{equation*}\par
\noindent We look for Euler-Lagrange equation for $\mathcal{L}(\theta,\hat{\theta})$:
\begin{equation*}
  \begin{gathered}
    L_{\hat{\theta}} -\dfrac{d}{dt}L_{\hat{\theta}} = 0\\
    -mgl\sin(\theta)-\dfrac{d}{dt}\left(ml^2\hat{\theta}\right) =0\\
    -mgl\sin(\theta)-ml^2\hat{\hat{\theta}} = 0\\
    = -gl\sin(\theta)-l^2\hat{\hat{\theta}} = 0\Rightarrow \hat{\hat{\theta}}+\dfrac{g}{l}\sin(\theta) = 0
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent When you consider small values of $\theta$ (small oscillations) around the equlibrium position ($\theta = 0$), then:
\begin{equation*}
  \begin{gathered}
    \hat{\hat{\theta}}+\dfrac{g}{l}\sin(\theta) = 0\Lrarr \hat{\hat{\theta}}+\dfrac{g}{l}\theta = 0\\
    \theta(t) = A\cos\left(\sqrt{\dfrac{g}{l}}t\right)+B\sin\left(\sqrt{\dfrac{g}{l}}t\right)
  \end{gathered}
\end{equation*}\par
\noindent Harmonic oscillations with frequency $\sqrt{\dfrac{g}{l}}$
\par\bigskip
\noindent The same equations can be obtained through Hamiltonian formalism: \par
\noindent Define the canonical momentum $p = \dfrac{\partial L}{\partial \hat{\theta}} = ml^2\hat{\theta}$\par
\noindent Invert the equation to find an expression for $\hat{\theta}$: $\hat{\theta} = \dfrac{p}{ml^2} =\Phi(p)$\par
\noindent $H(\theta, p) = -\mathcal{L}(\theta, \Phi(p)) + p\cdot \Phi(p)= \dfrac{-1}{2}ml^2\dfrac{p^2}{m^2l^4}+mgl-mgl\cos(\theta)+p\dfrac{p}{ml^2} = \dfrac{p^2}{2ml^2}-mgl\cos(\theta)+mgl$
\noindent Hamilton equations are given by $
\begin{cases*}
  \hat{p} = \dfrac{\partial H}{\partial \theta} = -mg\sin(\theta)\\\hat{\theta} = \dfrac{\partial H}{\partial p} = \dfrac{p}{ml^2}
\end{cases*}$
\par\bigskip
\noindent By computing $\hat{\hat{\theta}}$, we get the same equation that we fund for the Lagrangian.
\par\bigskip
\noindent\textbf{Example:} Central motion in the space.\par
\noindent There is a force that is raidal and you have a potential $V(r)$ that is dependent on some distance $r$ from your point.\par
\noindent In view of the radial symmetry, we can use spherical coordinates:
\begin{equation*}
  \begin{gathered}
    \begin{cases*}
      x = r\cos(\varphi)\sin(\theta)\\
      y = r\sin(\varphi)\sin(\theta)\\
      z = r\cos(\theta)
    \end{cases*}\Rightarrow (r,\varphi,\theta)
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent Want to write the kinetic energy, that is:
\begin{equation*}
  \begin{gathered}
    K = \dfrac{1}{2}m\left|\left|(\hat{x},\hat{y},\hat{z})\right|\right|^2 = \dfrac{1}{2}m(\hat{x}^2,\hat{y}^2,\hat{z}^2)
  \end{gathered}
\end{equation*}
\par\bigskip
\noindent In spherical coordinates one can write:
\begin{equation*}
  \begin{gathered}
    K = \dfrac{1}{2}m\left(\hat{r}^2+r^2\hat{\theta}^2+r^2\hat{\varphi}^2\sin^2(\theta)\right)\\
    \Rightarrow\mathcal{L} = K(r,\theta, \hat{r},\hat{\theta},\hat{\varphi})-V(r)
  \end{gathered}
\end{equation*}\par
\noindent Notice that the Lagrangian does not have an explicit dependance on $\varphi$, this can be used to define some constant of motion. To define the Hamiltonian, we will introduce the momenta:
\begin{equation*}
  \begin{gathered}
    p_r = L_{\hat{r}} = m\hat{r}\\
    p_\theta = L_{\hat{\theta}} = mr^2\hat{\theta}
    p_\varphi= L_{\hat{\varphi}} = mr^2\hat{\varphi}\sin^2(\theta)
  \end{gathered}
\end{equation*}\par
\noindent In the end, we will end up with a Hamiltonian that is dependant on $H(r,\theta,p_r,p_\varphi,p_\theta)$
\par\bigskip
\noindent Then, in the Hamiltonian equations:
\begin{equation*}
  \begin{gathered}
    \hat{p_\varphi} = -\dfrac{\partial H}{\partial \varphi} = 0\Rightarrow p_\varphi = C
  \end{gathered}
\end{equation*}\par
\noindent We can compute the constant and reduce the number of variables in our Hamiltonian 
\begin{equation*}
  \begin{gathered}
    \Rightarrow H(r,\theta,p_r,p_\theta)
  \end{gathered}
\end{equation*}
